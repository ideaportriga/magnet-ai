#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏ evaluation
"""

import asyncio
import os
import sys
from datetime import datetime, timezone

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))

from core.db.database import get_async_db
from services.evaluations.evaluations_service import EvaluationsService


async def test_evaluation_creation():
    """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏ evaluation"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ evaluation...")

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è evaluation
    evaluation_data = {
        "job_id": "test-job-123",
        "type": "agent_evaluation",
        "test_sets": [
            {
                "system_name": "MANUAL_TEST_SET",
                "id": "821e03d7-11b8-4ef4-9e7f-ec22e6d8a17d",
            }
        ],
        "started_at": datetime.now(timezone.utc),
        "status": "running",
        "errors": [],  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø - —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        "tool": {"type": "test_tool", "config": {}, "system_name": "TEST_TOOL"},
        "results": None,
    }

    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
        async for db in get_async_db():
            # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å
            evaluations_service = EvaluationsService(session=db)

            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å
            print(f"üìù –°–æ–∑–¥–∞–µ–º evaluation —Å –¥–∞–Ω–Ω—ã–º–∏: {evaluation_data}")
            evaluation = await evaluations_service.create(evaluation_data)

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞ evaluation —Å ID: {evaluation.id}")
            print("üìä –î–∞–Ω–Ω—ã–µ evaluation:")
            print(f"   - ID: {evaluation.id}")
            print(f"   - Job ID: {evaluation.job_id}")
            print(f"   - Type: {evaluation.type}")
            print(f"   - Status: {evaluation.status}")
            print(f"   - Test Sets: {evaluation.test_sets}")
            print(f"   - Started At: {evaluation.started_at}")
            print(f"   - Errors: {evaluation.errors}")
            print(f"   - Tool: {evaluation.tool}")

            return evaluation

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ evaluation: {e}")
        import traceback

        traceback.print_exc()
        return None


if __name__ == "__main__":
    asyncio.run(test_evaluation_creation())

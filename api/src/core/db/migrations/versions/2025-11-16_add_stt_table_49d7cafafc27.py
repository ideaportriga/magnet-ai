# type: ignore
"""add stt table

Revision ID: 49d7cafafc27
Revises: 12337df91a3e
Create Date: 2025-11-16 17:17:03.147326+00:00

"""

from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import (
    EncryptedString,
    EncryptedText,
    GUID,
    ORA_JSONB,
    DateTimeUTC,
)
from sqlalchemy import Text  # noqa: F401
import advanced_alchemy.types
import advanced_alchemy.types.datetime
import advanced_alchemy.types.json
from sqlalchemy.dialects import postgresql

if TYPE_CHECKING:
    pass

__all__ = [
    "downgrade",
    "upgrade",
    "schema_upgrades",
    "schema_downgrades",
    "data_upgrades",
    "data_downgrades",
]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
# Additional type aliases for proper migration generation
sa.Text = Text


# revision identifiers, used by Alembic.
revision = "49d7cafafc27"
down_revision = "12337df91a3e"
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()


def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()


def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "transcriptions",
        sa.Column(
            "id",
            sa.UUID(as_uuid=False),
            server_default=sa.text("gen_random_uuid()"),
            nullable=False,
        ),
        sa.Column(
            "file_id",
            sa.String(length=64),
            nullable=False,
            comment="External file/job id used by API",
        ),
        sa.Column("filename", sa.Text, nullable=True),
        sa.Column("file_ext", sa.String(length=16), nullable=True),
        sa.Column("object_key", sa.Text, nullable=True),
        sa.Column("content_type", sa.Text, nullable=True),
        sa.Column("duration_seconds", sa.Float(), nullable=True),
        sa.Column(
            "status",
            sa.String(length=50),
            server_default=sa.text("'started'"),
            nullable=False,
        ),
        sa.Column("error", sa.Text, nullable=True),
        sa.Column(
            "participants",
            sa.JSON()
            .with_variant(postgresql.JSONB(astext_type=sa.Text), "cockroachdb")
            .with_variant(advanced_alchemy.types.json.ORA_JSONB(), "oracle")
            .with_variant(postgresql.JSONB(astext_type=sa.Text), "postgresql"),
            nullable=True,
        ),
        sa.Column(
            "transcription",
            sa.JSON()
            .with_variant(postgresql.JSONB(astext_type=sa.Text), "cockroachdb")
            .with_variant(advanced_alchemy.types.json.ORA_JSONB(), "oracle")
            .with_variant(postgresql.JSONB(astext_type=sa.Text), "postgresql"),
            nullable=True,
        ),
        sa.Column("full_text", sa.Text, nullable=True),
        sa.Column(
            "created_at",
            advanced_alchemy.types.datetime.DateTimeUTC(timezone=True),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            advanced_alchemy.types.datetime.DateTimeUTC(timezone=True),
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_transcriptions")),
    )
    op.create_index(
        op.f("ix_transcriptions_file_id"), "transcriptions", ["file_id"], unique=True
    )
    op.create_index(
        op.f("ix_transcriptions_id"), "transcriptions", ["id"], unique=False
    )
    op.create_index(
        op.f("ix_transcriptions_object_key"),
        "transcriptions",
        ["object_key"],
        unique=False,
    )
    op.create_index(
        op.f("ix_transcriptions_status"), "transcriptions", ["status"], unique=False
    )
    op.drop_index(
        op.f("uq_agents_ms_teams_client_id"),
        table_name="agents",
        postgresql_where="(COALESCE(((channels -> 'ms_teams'::text) ->> 'client_id'::text), ''::text) <> ''::text)",
    )
    op.drop_index(
        op.f("uq_agents_slack_client_id"),
        table_name="agents",
        postgresql_where="(COALESCE(((channels -> 'slack'::text) ->> 'client_id'::text), ''::text) <> ''::text)",
    )
    op.drop_index(
        op.f("uq_agents_whatsapp_phone_number_id"),
        table_name="agents",
        postgresql_where="(COALESCE(((channels -> 'whatsapp'::text) ->> 'phone_number_id'::text), ''::text) <> ''::text)",
    )
    # ### end Alembic commands ###


def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(
        op.f("uq_agents_whatsapp_phone_number_id"),
        "agents",
        [sa.literal_column("(channels #>> '{whatsapp,phone_number_id}'::text[])")],
        unique=True,
        postgresql_where="(COALESCE(((channels -> 'whatsapp'::text) ->> 'phone_number_id'::text), ''::text) <> ''::text)",
    )
    op.create_index(
        op.f("uq_agents_slack_client_id"),
        "agents",
        [sa.literal_column("(channels #>> '{slack,client_id}'::text[])")],
        unique=True,
        postgresql_where="(COALESCE(((channels -> 'slack'::text) ->> 'client_id'::text), ''::text) <> ''::text)",
    )
    op.create_index(
        op.f("uq_agents_ms_teams_client_id"),
        "agents",
        [sa.literal_column("(channels #>> '{ms_teams,client_id}'::text[])")],
        unique=True,
        postgresql_where="(COALESCE(((channels -> 'ms_teams'::text) ->> 'client_id'::text), ''::text) <> ''::text)",
    )
    op.drop_index(op.f("ix_transcriptions_status"), table_name="transcriptions")
    op.drop_index(op.f("ix_transcriptions_object_key"), table_name="transcriptions")
    op.drop_index(op.f("ix_transcriptions_id"), table_name="transcriptions")
    op.drop_index(op.f("ix_transcriptions_file_id"), table_name="transcriptions")
    op.drop_table("transcriptions")
    # ### end Alembic commands ###


def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""


def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""

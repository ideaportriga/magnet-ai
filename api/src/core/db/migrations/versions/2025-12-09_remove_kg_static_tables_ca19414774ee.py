# type: ignore
"""remove kg static tables

Revision ID: ca19414774ee
Revises: 7b9a2f4d1c3e
Create Date: 2025-12-09 14:53:32.762556+00:00

"""

from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import (
    EncryptedString,
    EncryptedText,
    GUID,
    ORA_JSONB,
    DateTimeUTC,
)
from sqlalchemy import Text  # noqa: F401
from sqlalchemy.dialects import postgresql

if TYPE_CHECKING:
    pass

__all__ = [
    "downgrade",
    "upgrade",
    "schema_upgrades",
    "schema_downgrades",
    "data_upgrades",
    "data_downgrades",
]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
# Additional type aliases for proper migration generation
sa.Text = Text


# revision identifiers, used by Alembic.
revision = "ca19414774ee"
down_revision = "7b9a2f4d1c3e"
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()


def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()


def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("knowledge_graph_chunks")
    op.drop_table("knowledge_graph_documents")
    # ### end Alembic commands ###


def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###

    op.create_table(
        "knowledge_graph_documents",
        sa.Column(
            "type",
            sa.VARCHAR(length=100),
            autoincrement=False,
            nullable=True,
            comment="Document type (e.g., 'pdf', 'doc')",
        ),
        sa.Column(
            "summary",
            sa.TEXT(),
            autoincrement=False,
            nullable=True,
            comment="Document summary",
        ),
        sa.Column(
            "embedding",
            postgresql.JSONB(astext_type=sa.Text),
            autoincrement=False,
            nullable=True,
            comment="Embedding vector for the document",
        ),
        sa.Column(
            "status",
            sa.VARCHAR(length=50),
            autoincrement=False,
            nullable=True,
            comment="Processing status (pending, processing, completed, error)",
        ),
        sa.Column(
            "total_pages",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
            comment="Total number of pages in the document",
        ),
        sa.Column(
            "name",
            sa.VARCHAR(length=255),
            autoincrement=False,
            nullable=False,
            comment="Source name",
        ),
        sa.Column("id", sa.UUID(), autoincrement=False, nullable=False),
        sa.Column("sa_orm_sentinel", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "graph_id",
            sa.UUID(),
            autoincrement=False,
            nullable=True,
            comment="Foreign key to knowledge_graphs",
        ),
        sa.Column(
            "source_id",
            sa.UUID(),
            autoincrement=False,
            nullable=True,
            comment="Foreign key to knowledge_graph_sources",
        ),
        sa.Column(
            "title",
            sa.VARCHAR(length=500),
            autoincrement=False,
            nullable=True,
            comment="Document title",
        ),
        sa.Column(
            "toc",
            postgresql.JSONB(astext_type=sa.Text),
            autoincrement=False,
            nullable=True,
            comment="Document table of contents",
        ),
        sa.Column(
            "status_message",
            sa.TEXT(),
            autoincrement=False,
            nullable=True,
            comment="Processing status message",
        ),
        sa.Column(
            "content_profile",
            sa.VARCHAR(length=100),
            autoincrement=False,
            nullable=True,
            comment="Content profile name used for ingestion",
        ),
        sa.Column(
            "processing_time",
            sa.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
            comment="Processing time in seconds",
        ),
        sa.ForeignKeyConstraint(
            ["graph_id"],
            ["knowledge_graphs.id"],
            name="fk_knowledge_graph_documents_graph_id_knowledge_graphs",
            ondelete="SET NULL",
        ),
        sa.ForeignKeyConstraint(
            ["source_id"],
            ["knowledge_graph_sources.id"],
            name="fk_knowledge_graph_documents_source_id_knowledge_graph_sources",
            ondelete="SET NULL",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_knowledge_graph_documents"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "knowledge_graph_chunks",
        sa.Column(
            "generated_id",
            sa.VARCHAR(length=1000),
            autoincrement=False,
            nullable=True,
            comment="Generated ID from AI chunking process",
        ),
        sa.Column(
            "title",
            sa.VARCHAR(length=500),
            autoincrement=False,
            nullable=True,
            comment="Chunk title",
        ),
        sa.Column(
            "page",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
            comment="Page number where the chunk starts",
        ),
        sa.Column(
            "text",
            sa.TEXT(),
            autoincrement=False,
            nullable=True,
            comment="Chunk text content",
        ),
        sa.Column(
            "embedding",
            postgresql.JSONB(astext_type=sa.Text),
            autoincrement=False,
            nullable=True,
            comment="Embedding vector for the chunk",
        ),
        sa.Column(
            "chunk_type",
            sa.VARCHAR(length=50),
            autoincrement=False,
            nullable=True,
            comment="Chunk type (TEXT, TABLE, etc.)",
        ),
        sa.Column(
            "document_id",
            sa.UUID(),
            autoincrement=False,
            nullable=True,
            comment="Foreign key to knowledge_graph_documents",
        ),
        sa.Column(
            "name",
            sa.VARCHAR(length=255),
            autoincrement=False,
            nullable=False,
            comment="Source name",
        ),
        sa.Column("id", sa.UUID(), autoincrement=False, nullable=False),
        sa.Column("sa_orm_sentinel", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "index",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
            comment="Chunk index in the document",
        ),
        sa.Column(
            "toc_reference",
            sa.VARCHAR(length=500),
            autoincrement=False,
            nullable=True,
            comment="TOC reference",
        ),
        sa.ForeignKeyConstraint(
            ["document_id"],
            ["knowledge_graph_documents.id"],
            name=op.f(
                "fk_knowledge_graph_chunks_document_id_knowledge_graph_documents"
            ),
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_knowledge_graph_chunks")),
    )
    # ### end Alembic commands ###


def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""


def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""

# type: ignore
"""initial migration

Revision ID: ed46129c2799
Revises: 
Create Date: 2025-09-17 06:39:18.909525+00:00

"""
from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import EncryptedString, EncryptedText, GUID, ORA_JSONB, DateTimeUTC
from sqlalchemy import Text  # noqa: F401
import advanced_alchemy.types
import advanced_alchemy.types.datetime
import advanced_alchemy.types.json
from sqlalchemy.dialects import postgresql
from advanced_alchemy.types import GUID
from core.db.models.mcp_server.mcp_server import EncryptedJsonB
from sqlalchemy import Text
from sqlalchemy.dialects import postgresql
if TYPE_CHECKING:
    from collections.abc import Sequence

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
# Additional type aliases for proper migration generation
sa.Text = Text


# revision identifiers, used by Alembic.
revision = 'ed46129c2799'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()

def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()

def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('api_servers',
    sa.Column('url', sa.String(), nullable=False, comment='API server URL'),
    sa.Column('security_scheme', sa.JSON().with_variant(postgresql.JSONB(astext_type=sa.Text), 'cockroachdb').with_variant(advanced_alchemy.types.json.ORA_JSONB(), 'oracle').with_variant(postgresql.JSONB(astext_type=sa.Text), 'postgresql'), nullable=True, comment='Security scheme configuration'),
    sa.Column('security_values', sa.JSON().with_variant(postgresql.JSONB(astext_type=sa.Text), 'cockroachdb').with_variant(advanced_alchemy.types.json.ORA_JSONB(), 'oracle').with_variant(postgresql.JSONB(astext_type=sa.Text), 'postgresql'), nullable=True, comment='Security values configuration'),
    sa.Column('verify_ssl', sa.Boolean(), nullable=False, comment='SSL verification flag'),
    sa.Column('tools', sa.JSON().with_variant(postgresql.JSONB(astext_type=sa.Text), 'cockroachdb').with_variant(advanced_alchemy.types.json.ORA_JSONB(), 'oracle').with_variant(postgresql.JSONB(astext_type=sa.Text), 'postgresql'), nullable=True, comment='Tools configuration as array of dictionaries'),
    sa.Column('secrets_encrypted', EncryptedJsonB(key='my-secret-key'), nullable=True, comment='Encrypted secrets configuration'),
    sa.Column('name', sa.String(length=255), nullable=False, comment='Entity name'),
    sa.Column('description', sa.Text, nullable=True, comment='Entity description'),
    sa.Column('system_name', sa.String(length=255), nullable=False, comment='System name of the entity'),
    sa.Column('category', sa.String(length=255), nullable=True, comment='Entity category'),
    sa.Column('created_by', sa.String(length=36), nullable=True, comment='ID of the user who created the entity'),
    sa.Column('updated_by', sa.String(length=36), nullable=True, comment='ID of the user who last updated the entity'),
    sa.Column('id', GUID, nullable=False),
    sa.Column('sa_orm_sentinel', sa.Integer(), nullable=True),
    sa.Column('created_at', advanced_alchemy.types.datetime.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('updated_at', advanced_alchemy.types.datetime.DateTimeUTC(timezone=True), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_servers')),
    sa.UniqueConstraint('system_name', name=op.f('uq_api_servers_system_name'))
    )
    op.create_index(op.f('ix_api_servers_description'), 'api_servers', ['description'], unique=False)
    op.create_index(op.f('ix_api_servers_name'), 'api_servers', ['name'], unique=False)
    op.drop_index(op.f('ix_apscheduler_jobs_next_run_time'), table_name='apscheduler_jobs')
    op.drop_table('apscheduler_jobs')
    op.drop_index(op.f('idx_documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f_embedding_co'), table_name='documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f', postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
    op.drop_index(op.f('idx_documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f_metadata_gin'), table_name='documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f', postgresql_using='gin')
    op.drop_table('documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f')
    # ### end Alembic commands ###

def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('content', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text), autoincrement=False, nullable=True),
    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f_pkey'))
    )
    op.create_index(op.f('idx_documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f_metadata_gin'), 'documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f', ['metadata'], unique=False, postgresql_using='gin')
    op.create_index(op.f('idx_documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f_embedding_co'), 'documents_6ded6919_8910_49ce_88a4_f0adf5cdf28f', ['embedding'], unique=False, postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
    op.create_table('apscheduler_jobs',
    sa.Column('id', sa.VARCHAR(length=191), autoincrement=False, nullable=False),
    sa.Column('next_run_time', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('job_state', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('apscheduler_jobs_pkey'))
    )
    op.create_index(op.f('ix_apscheduler_jobs_next_run_time'), 'apscheduler_jobs', ['next_run_time'], unique=False)
    op.drop_index(op.f('ix_api_servers_name'), table_name='api_servers')
    op.drop_index(op.f('ix_api_servers_description'), table_name='api_servers')
    op.drop_table('api_servers')
    # ### end Alembic commands ###

def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""

def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""

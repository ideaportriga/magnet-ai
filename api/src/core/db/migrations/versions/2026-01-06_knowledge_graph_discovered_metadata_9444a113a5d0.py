# type: ignore
"""knowledge_graph_discovered_metadata

Revision ID: 9444a113a5d0
Revises: c3b1a6e8d0f2
Create Date: 2026-01-06 22:06:09.148989+00:00

"""
from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import EncryptedString, EncryptedText, GUID, ORA_JSONB, DateTimeUTC
from sqlalchemy import Text  # noqa: F401
import advanced_alchemy.types
import advanced_alchemy.types.datetime
import advanced_alchemy.types.json
from sqlalchemy.dialects import postgresql
if TYPE_CHECKING:
    pass

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
# Additional type aliases for proper migration generation
sa.Text = Text


# revision identifiers, used by Alembic.
revision = '9444a113a5d0'
down_revision = 'c3b1a6e8d0f2'
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()

def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()

def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('knowledge_graph_discovered_metadata',
    sa.Column('id', GUID, nullable=False),
    sa.Column('graph_id', GUID, nullable=False, comment='Foreign key to knowledge_graphs'),
    sa.Column('name', sa.String(length=255), nullable=False, comment='Discovered metadata field name'),
    sa.Column('inferred_type', sa.String(length=50), nullable=True, comment='Inferred metadata value type (string, number, boolean, date, ...)'),
    sa.Column('origins', sa.JSON().with_variant(postgresql.JSONB(astext_type=sa.Text), 'cockroachdb').with_variant(advanced_alchemy.types.json.ORA_JSONB(), 'oracle').with_variant(postgresql.JSONB(astext_type=sa.Text), 'postgresql'), nullable=True, comment='Origins where this field was observed (e.g. document, llm, source)'),
    sa.Column('sample_values', sa.JSON().with_variant(postgresql.JSONB(astext_type=sa.Text), 'cockroachdb').with_variant(advanced_alchemy.types.json.ORA_JSONB(), 'oracle').with_variant(postgresql.JSONB(astext_type=sa.Text), 'postgresql'), nullable=True, comment='Sample values observed for this field (best-effort, limited set)'),
    sa.Column('value_count', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Total number of values observed for this field (best-effort aggregation)'),
    sa.Column('sa_orm_sentinel', sa.Integer(), nullable=True),
    sa.Column('created_at', advanced_alchemy.types.datetime.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('updated_at', advanced_alchemy.types.datetime.DateTimeUTC(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['graph_id'], ['knowledge_graphs.id'], name=op.f('fk_knowledge_graph_discovered_metadata_graph_id_knowledge_graphs'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_knowledge_graph_discovered_metadata')),
    sa.UniqueConstraint('graph_id', 'name', name='uq_knowledge_graph_discovered_metadata_fields_graph_id_name')
    )
    op.create_index(op.f('ix_knowledge_graph_discovered_metadata_graph_id'), 'knowledge_graph_discovered_metadata', ['graph_id'], unique=False)
    op.create_index(op.f('ix_knowledge_graph_discovered_metadata_name'), 'knowledge_graph_discovered_metadata', ['name'], unique=False)
    op.create_table('knowledge_graph_sources_discovered_metadata',
    sa.Column('source_id', GUID, nullable=False),
    sa.Column('discovered_metadata_id', GUID, nullable=False),
    sa.ForeignKeyConstraint(['discovered_metadata_id'], ['knowledge_graph_discovered_metadata.id'], name=op.f('fk_knowledge_graph_sources_discovered_metadata_discovered_metadata_id_knowledge_graph_discovered_metadata'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['source_id'], ['knowledge_graph_sources.id'], name=op.f('fk_knowledge_graph_sources_discovered_metadata_source_id_knowledge_graph_sources'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('source_id', 'discovered_metadata_id', name=op.f('pk_knowledge_graph_sources_discovered_metadata'))
    )
    op.alter_column('teams_meeting', 'meeting_id',
               existing_type=sa.TEXT(),
               comment='Teams meeting id from channel data',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'bot_id',
               existing_type=sa.TEXT(),
               comment='Bot app id installed in meeting',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_user_id',
               existing_type=sa.TEXT(),
               comment='Teams user id of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_aad_object_id',
               existing_type=sa.TEXT(),
               comment='AAD object id of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_display_name',
               existing_type=sa.TEXT(),
               comment='Display name of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_to_meeting_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Timestamp when the bot was added to the meeting',
               existing_nullable=True)
    # ### end Alembic commands ###

def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('teams_meeting', 'added_to_meeting_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Timestamp when the bot was added to the meeting',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_display_name',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Display name of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_aad_object_id',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='AAD object id of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'added_by_user_id',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Teams user id of the user who added the bot',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'bot_id',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Bot app id installed in meeting',
               existing_nullable=True)
    op.alter_column('teams_meeting', 'meeting_id',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Teams meeting id from channel data',
               existing_nullable=True)
    op.drop_table('knowledge_graph_sources_discovered_metadata')
    op.drop_index(op.f('ix_knowledge_graph_discovered_metadata_name'), table_name='knowledge_graph_discovered_metadata')
    op.drop_index(op.f('ix_knowledge_graph_discovered_metadata_graph_id'), table_name='knowledge_graph_discovered_metadata')
    op.drop_table('knowledge_graph_discovered_metadata')
    # ### end Alembic commands ###

def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""

def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""

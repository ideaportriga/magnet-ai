"""Alembic environment configuration."""

import asyncio
import re
from typing import Optional

from advanced_alchemy.base import UUIDAuditBase

# import sys
# from logging.config import fileConfig
# from pathlib import Path
from alembic import context
from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config

from core.config.base import get_settings
from core.db.models.agent import Agent  # noqa: F401
from core.db.models.agent_conversation import AgentConversation  # noqa: F401
from core.db.models.ai_app import AIApp  # noqa: F401
from core.db.models.ai_model import AIModel  # noqa: F401
from core.db.models.api_server import APIServer  # noqa: F401
from core.db.models.api_tool import APITool  # noqa: F401

# Import specific models to register them with metadata
from core.db.models.base import UUIDAuditEntityBase  # noqa: F401
from core.db.models.collection import Collection  # noqa: F401
from core.db.models.deep_research import (  # noqa: F401
    DeepResearchConfig,
    DeepResearchRun,
)
from core.db.models.evaluation import Evaluation  # noqa: F401
from core.db.models.evaluation_set import EvaluationSet  # noqa: F401
from core.db.models.knowledge_graph import (  # noqa: F401
    KnowledgeGraph,
    KnowledgeGraphMetadataDiscovery,
    KnowledgeGraphSource,
)
from core.db.models.mcp_server import MCPServer  # noqa: F401
from core.db.models.mcp_server.mcp_server import EncryptedJsonB  # noqa: F401
from core.db.models.metric import Metric  # noqa: F401
from core.db.models.prompt import Prompt  # noqa: F401
from core.db.models.provider import Provider  # noqa: F401
from core.db.models.rag_tool.rag_tool import RagTool  # noqa: F401
from core.db.models.retrieval_tool import RetrievalTool  # noqa: F401
from core.db.models.slack import SlackInstallation, SlackOAuthState  # noqa: F401
from core.db.models.teams import TeamsMeeting  # noqa: F401
from core.db.models.teams.note_taker_settings import NoteTakerSettings  # noqa: F401
from core.db.models.trace import Trace  # noqa: F401
from core.db.models.transcription.transcription import Transcription  # noqa: F401

# Add the src directory to the Python path
# src_path = Path(__file__).parent.parent.parent
# sys.path.insert(0, str(src_path))

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
# if config.config_file_name is not None:
#     fileConfig(config.config_file_name)

# Get the SQLAlchemy URL from our app configuration
settings = get_settings()
# Use effective_url which builds URL from individual components if DATABASE_URL is not set
effective_url = settings.db.effective_url
# Escape % characters in the URL to prevent ConfigParser interpolation issues
escaped_url = effective_url.replace("%", "%%") if effective_url else ""
config.set_main_option("sqlalchemy.url", escaped_url)

# add your model's MetaData object here
# for 'autogenerate' support
target_metadata = UUIDAuditBase.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """

    def include_object(object, name, type_, reflected, compare_to):
        """Exclude specific tables from autogeneration.

        This function is called for every object in the schema to determine
        if it should be included in the autogenerated migration.

        Returns False to exclude the object from the migration.
        """
        if type_ == "table":
            # Ignore dynamically created document tables (vector store)
            if name.startswith("documents_"):
                return False
            # Ignore APScheduler tables
            if name == "apscheduler_jobs":
                return False
            # Ignore knowledge graph tables
            if re.match(r"knowledge_graph_.*_(chunks|docs|documents)$", name):
                return False
        elif type_ == "index":
            # Ignore knowledge graph indexes
            if re.match(r"idx_kg_.*_(chunks|docs|documents|docume).*", name):
                return False
            if re.match(
                r"idx_knowledge_graph_.*_(chunks|docs|documents|docume).*", name
            ):
                return False
        return True

    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        version_table=settings.db.MIGRATION_DDL_VERSION_TABLE,
        include_object=include_object,
        # Configure imports for autogeneration
        imports=[
            "from sqlalchemy import Text",
            "from advanced_alchemy.types import GUID",
            "from core.db.models.mcp_server.mcp_server import EncryptedJsonB",
        ],
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection: Connection) -> None:
    """Run migrations with a database connection."""

    def include_object(object, name, type_, reflected, compare_to):
        """Exclude specific tables from autogeneration.

        This function is called for every object in the schema to determine
        if it should be included in the autogenerated migration.

        Returns False to exclude the object from the migration.
        """
        if type_ == "table":
            # Ignore dynamically created document tables (vector store)
            if name.startswith("documents_"):
                return False
            # Ignore APScheduler tables
            if name == "apscheduler_jobs":
                return False
            # Ignore knowledge graph tables
            if re.match(r"knowledge_graph_.*_(chunks|docs|documents)$", name):
                return False
        elif type_ == "index":
            # Ignore knowledge graph indexes
            if re.match(r"idx_kg_.*_(chunks|docs|documents|docume).*", name):
                return False
            if re.match(
                r"idx_knowledge_graph_.*_(chunks|docs|documents|docume).*", name
            ):
                return False
        return True

    def render_item(type_, obj, autogen_context):
        """Custom renderer for types to handle imports."""
        if type_ == "type":
            # Handle Text type
            if hasattr(obj, "__class__") and obj.__class__.__name__ == "Text":
                autogen_context.imports.add("from sqlalchemy import Text")
                return "sa.Text"
            # Handle GUID type
            elif hasattr(obj, "__class__") and "GUID" in obj.__class__.__name__:
                autogen_context.imports.add("from advanced_alchemy.types import GUID")
                return "GUID"
            elif (
                hasattr(obj, "__class__") and obj.__class__.__name__ == "EncryptedJsonB"
            ):
                autogen_context.imports.add(
                    "from core.db.models.mcp_server.mcp_server import EncryptedJsonB"
                )
                # EncryptedJsonB requires a key parameter
                if hasattr(obj, "encrypted_type") and hasattr(
                    obj.encrypted_type, "key"
                ):
                    key = obj.encrypted_type.key
                    return f"EncryptedJsonB(key='{key}')"
                else:
                    # Fallback if key is not accessible
                    return "EncryptedJsonB(key='default-key')"
        return False

    def compare_type(
        context, inspected_column, metadata_column, inspected_type, metadata_type
    ) -> Optional[bool]:
        """Custom type comparison for autogeneration."""
        if (
            hasattr(metadata_type, "__class__")
            and metadata_type.__class__.__name__ == "EncryptedJsonB"
        ):
            # Check if the inspected type is also EncryptedJsonB or compatible TEXT
            if hasattr(inspected_type, "__class__"):
                inspected_class_name = inspected_type.__class__.__name__
                if inspected_class_name in ("EncryptedJsonB", "TEXT", "Text"):
                    # For EncryptedJsonB, also check if the key matches
                    if inspected_class_name == "EncryptedJsonB":
                        # Compare encryption keys if accessible
                        metadata_key = getattr(
                            getattr(metadata_type, "encrypted_type", None), "key", None
                        )
                        inspected_key = getattr(
                            getattr(inspected_type, "encrypted_type", None), "key", None
                        )
                        return metadata_key != inspected_key
                    # If inspected type is TEXT, no migration needed as they're compatible
                    return False
            # If not compatible, we need a migration
            return True

        # For all other types, use default comparison
        return None

    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        version_table=settings.db.MIGRATION_DDL_VERSION_TABLE,
        render_item=render_item,
        compare_type=compare_type,
        include_object=include_object,
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """Run migrations in an async context."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    asyncio.run(run_async_migrations())


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
